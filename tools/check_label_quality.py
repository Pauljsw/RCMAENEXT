# tools/check_label_quality.py
"""
ë¼ë²¨ í’ˆì§ˆ ê²€ì¦ ë° ë¶€ë¶„ ì·¨ë“ ê°ì§€ ë„êµ¬

ë¶€ë¶„ ì·¨ë“ëœ ê°ì²´ë¥¼ ê°ì§€í•˜ê³  anchor ì „ëµì„ ê°œì„ 
"""

import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import json


class LabelQualityChecker:
    """ë¼ë²¨ í’ˆì§ˆ ê²€ì¦ê¸°"""
    
    def __init__(self, optimized_config_path):
        # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        with open(optimized_config_path, 'r') as f:
            self.config = json.load(f)
        
        self.statistics = self.config['statistics']
        print("ğŸ” ë¼ë²¨ í’ˆì§ˆ ê²€ì¦ ì‹œì‘")
    
    def detect_partial_objects(self):
        """ë¶€ë¶„ ì·¨ë“ ê°ì²´ ê°ì§€"""
        print("\nğŸ“Š ë¶€ë¶„ ì·¨ë“ ê°ì²´ ë¶„ì„...")
        
        partial_detection = {}
        
        for class_name, stats in self.statistics.items():
            if stats['count'] == 0:
                continue
                
            # IQR ê¸°ë°˜ ì´ìƒê°’ ê°ì§€
            length_data = np.array([])  # ì‹¤ì œ ë°ì´í„° í•„ìš”
            
            # í†µê³„ ê¸°ë°˜ ë¶„ì„
            mean_length = stats['length']['mean']
            std_length = stats['length']['std']
            q25_length = stats['length']['q25']
            q75_length = stats['length']['q75']
            
            # IQR ê¸°ë°˜ ì´ìƒê°’ ê²½ê³„
            iqr = q75_length - q25_length
            lower_bound = q25_length - 1.5 * iqr
            upper_bound = q75_length + 1.5 * iqr
            
            # ë¶€ë¶„ ì·¨ë“ ì˜ì‹¬ ë¹„ìœ¨ ê³„ì‚°
            normal_size = mean_length
            partial_threshold = normal_size * 0.6  # 60% ë¯¸ë§Œì´ë©´ ë¶€ë¶„ ì·¨ë“ ì˜ì‹¬
            
            partial_ratio = max(0, (partial_threshold - stats['length']['min']) / 
                              (stats['length']['max'] - stats['length']['min']))
            
            partial_detection[class_name] = {
                'normal_size': normal_size,
                'partial_threshold': partial_threshold,
                'min_size': stats['length']['min'],
                'max_size': stats['length']['max'],
                'suspected_partial_ratio': partial_ratio,
                'iqr_lower': lower_bound,
                'iqr_upper': upper_bound
            }
            
            print(f"\nğŸ—ï¸ {class_name}:")
            print(f"   ğŸ“ ì •ìƒ í¬ê¸°: {normal_size:.1f}m")
            print(f"   âš ï¸ ë¶€ë¶„ ì·¨ë“ ì˜ì‹¬ ê¸°ì¤€: <{partial_threshold:.1f}m")
            print(f"   ğŸ“Š í¬ê¸° ë²”ìœ„: {stats['length']['min']:.1f}~{stats['length']['max']:.1f}m")
            print(f"   ğŸ” ë¶€ë¶„ ì·¨ë“ ì˜ì‹¬ ë¹„ìœ¨: {partial_ratio*100:.1f}%")
        
        return partial_detection
    
    def generate_multiscale_anchors(self, partial_detection):
        """ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ Anchor ìƒì„±"""
        print("\nğŸ¯ Multi-scale Anchor ìƒì„±...")
        
        multiscale_config = []
        
        for class_name in ['dumptruck', 'excavator', 'grader', 'roller']:
            if class_name not in self.statistics or class_name not in partial_detection:
                continue
                
            stats = self.statistics[class_name]
            partial_info = partial_detection[class_name]
            
            # ì›ë³¸ ìµœì  í¬ê¸°
            optimal_size = [
                round(stats['length']['median'], 1),
                round(stats['width']['median'], 1),
                round(stats['height']['median'], 1)
            ]
            
            # ë¶€ë¶„ ì·¨ë“ ê³ ë ¤ í¬ê¸° (70% í¬ê¸°)
            partial_size = [
                round(optimal_size[0] * 0.7, 1),
                round(optimal_size[1] * 0.8, 1),  # í­ì€ ëœ ë³€í•¨
                round(optimal_size[2] * 0.9, 1)   # ë†’ì´ëŠ” ê±°ì˜ ë³€í•˜ì§€ ì•ŠìŒ
            ]
            
            # ëŒ€í˜• í¬ê¸° (120% í¬ê¸°)
            large_size = [
                round(optimal_size[0] * 1.2, 1),
                round(optimal_size[1] * 1.1, 1),
                round(optimal_size[2] * 1.1, 1)
            ]
            
            # ë‹¨ì¼ í¬ê¸° vs ë‹¤ì¤‘ í¬ê¸° ì„ íƒ
            if partial_info['suspected_partial_ratio'] > 0.2:  # 20% ì´ìƒ ë¶€ë¶„ ì·¨ë“
                anchor_sizes = [partial_size, optimal_size, large_size]
                strategy = "Multi-scale (ë¶€ë¶„ ì·¨ë“ ê³ ë ¤)"
            else:
                anchor_sizes = [optimal_size]
                strategy = "Single-scale (í’ˆì§ˆ ì–‘í˜¸)"
            
            config = {
                'class_name': class_name,
                'anchor_sizes': anchor_sizes,
                'anchor_rotations': [0, 1.57],
                'anchor_bottom_heights': [-1.78],
                'align_center': False,
                'feature_map_stride': 8,
                'matched_threshold': 0.6,
                'unmatched_threshold': 0.45
            }
            
            multiscale_config.append(config)
            
            print(f"   ğŸ—ï¸ {class_name}: {strategy}")
            print(f"      Anchor sizes: {anchor_sizes}")
        
        return multiscale_config
    
    def generate_improved_config(self):
        """ê°œì„ ëœ ì„¤ì • ìƒì„±"""
        partial_detection = self.detect_partial_objects()
        multiscale_config = self.generate_multiscale_anchors(partial_detection)
        
        print("\nâš™ï¸ ê°œì„ ëœ ANCHOR_GENERATOR_CONFIG:")
        print("```yaml")
        print("ANCHOR_GENERATOR_CONFIG: [")
        for config in multiscale_config:
            print("    {")
            for key, value in config.items():
                if isinstance(value, str):
                    print(f"        '{key}': '{value}',")
                else:
                    print(f"        '{key}': {value},")
            print("    },")
        print("]")
        print("```")
        
        # ê°œì„ ëœ ì„¤ì • ì €ì¥
        improved_config = {
            'partial_detection_analysis': partial_detection,
            'multiscale_anchor_config': multiscale_config,
            'recommendations': self._generate_recommendations(partial_detection)
        }
        
        with open('improved_anchor_config.json', 'w') as f:
            json.dump(improved_config, f, indent=2)
        
        print(f"\nğŸ’¾ ê°œì„ ëœ ì„¤ì • ì €ì¥: improved_anchor_config.json")
        return improved_config
    
    def _generate_recommendations(self, partial_detection):
        """ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        for class_name, info in partial_detection.items():
            if info['suspected_partial_ratio'] > 0.3:
                recommendations.append({
                    'class': class_name,
                    'issue': 'High partial acquisition suspected',
                    'action': 'Use multi-scale anchors',
                    'priority': 'High'
                })
            elif info['suspected_partial_ratio'] > 0.1:
                recommendations.append({
                    'class': class_name,
                    'issue': 'Moderate partial acquisition',
                    'action': 'Consider data cleaning',
                    'priority': 'Medium'
                })
        
        return recommendations


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ” ë¼ë²¨ í’ˆì§ˆ ê²€ì¦ ë° ê°œì„  ë„êµ¬")
    print("="*50)
    
    config_path = 'optimized_anchor_config.json'
    
    if not Path(config_path).exists():
        print(f"âŒ {config_path}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        print("   ë¨¼ì € analyze_dataset_anchors.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    checker = LabelQualityChecker(config_path)
    improved_config = checker.generate_improved_config()
    
    print("\nğŸ¯ ê¶Œì¥ì‚¬í•­:")
    for rec in improved_config['recommendations']:
        print(f"   ğŸ—ï¸ {rec['class']}: {rec['action']} ({rec['priority']} priority)")
    
    print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. improved_anchor_config.json í™•ì¸")
    print("   2. Multi-scale anchor ì ìš© ê³ ë ¤")
    print("   3. ë¶€ë¶„ ì·¨ë“ ë°ì´í„° ê²€í†  ë° ì •ì œ")


if __name__ == "__main__":
    main()