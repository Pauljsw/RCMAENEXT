# cfgs/custom_models/rmae_cmae_isarc_4class_pretraining_phase1.yaml


# âœ… ê¸°ì¡´ê³¼ ë™ì¼í•œ í´ë˜ìŠ¤ëª… ì‚¬ìš©
CLASS_NAMES: ['dumptruck', 'excavator', 'grader', 'roller']

DATA_CONFIG:
    # âœ… ê¸°ì¡´ê³¼ ë™ì¼í•œ base config ì‚¬ìš©
    _BASE_CONFIG_: cfgs/dataset_configs/custom_dataset_isarc.yaml
    
    # âœ… ê¸°ì¡´ R-MAE pretrainingê³¼ ë™ì¼í•œ augmentation (gt_sampling ë¹„í™œì„±í™”)
    DATA_AUGMENTOR:
        DISABLE_AUG_LIST: ['gt_sampling']  # pretrainingì—ì„œëŠ” gt_sampling ë¹„í™œì„±í™”
        AUG_CONFIG_LIST:
            - NAME: random_world_flip
              ALONG_AXIS_LIST: ['x']
            - NAME: random_world_scaling
              WORLD_SCALE_RANGE: [0.98, 1.02]  # ê¸°ì¡´ê³¼ ë™ì¼

MODEL:
    NAME: RMAECMAEDetectorPhase1  # ğŸ”¥ ìƒˆë¡œìš´ Phase 1 detector

    VFE:
        NAME: MeanVFE

    BACKBONE_3D:
        NAME: RMAECMAEBackbonePhase1  # ğŸ”¥ ìƒˆë¡œìš´ Phase 1 backbone
        
        # ===== ğŸ“„ ê¸°ì¡´ R-MAE ì„¤ì • ì™„ì „ ë³µì‚¬ =====
        MASKED_RATIO: 0.8
        
        # Stage 1: Angular Group Selection
        NUM_ANGULAR_GROUPS: 36          # Ng = 36 groups
        ANGULAR_GROUP_SIZE: 10          # Î”Î¸ = 10 degrees (360/36)
        
        # Stage 2: 10m/30m ê¸°ì¤€ Range-Aware Masking 
        DISTANCE_THRESHOLDS: [10, 30]   # Nearâ‰¤10m, Mid 10~30m, Far>30m
        RANGE_MASK_PROBS:               # 10m/30m ê¸°ì¤€ ë§ˆìŠ¤í‚¹ í™•ë¥ 
            NEAR: 0.50      # Nearâ‰¤10m: 50% ë§ˆìŠ¤í‚¹ (ì„¸ë¶€ì‚¬í•­ ë³´ì¡´)
            MID: 0.75       # Mid 10~30m: 75% ë§ˆìŠ¤í‚¹ (í‘œì¤€)
            FAR: 0.90       # Far>30m: 90% ë§ˆìŠ¤í‚¹ (ë†’ì€ ë§ˆìŠ¤í‚¹)
        
        # ë…¼ë¬¸ êµ¬í˜„ ì˜µì…˜
        USE_BERNOULLI_MASKING: True     # Bernoulli distribution ì‚¬ìš©
        ENABLE_2STAGE_MASKING: True     # 2-Stage masking í™œì„±í™”
        
        # ===== ğŸ”¥ Phase 1: Teacher-Student ì„¤ì • =====
        ENABLE_TEACHER_STUDENT: True      # Teacher-Student architecture í™œì„±í™”
        TEACHER_STUDENT_MODE: 'phase1'    # Phase 1 ëª¨ë“œ
        
        # Teacher-Student íŒŒë¼ë¯¸í„° (Phase 1ì—ì„œëŠ” ê¸°ë³¸ê°’)
        TEACHER_BACKBONE_TYPE: 'identical'  # Teacher = Student backbone (í˜„ì¬)
        FEATURE_DIM: 128                    # Feature projection ì°¨ì›
        
        # ğŸ“ Pretraining ëª¨ë“œ ì„¤ì •
        PRETRAINING: True                   # R-MAE occupancy prediction í™œì„±í™”

    # âœ… Pretraining ëª¨ë“œì—ì„œëŠ” DENSE_HEAD ì œê±° (R-MAE í‘œì¤€)

    POST_PROCESSING:
        RECALL_THRESH_LIST: [0.3, 0.5, 0.7]
        EVAL_METRIC: kitti

# ===== ğŸš€ Loss ê°€ì¤‘ì¹˜ ì„¤ì • =====  
LOSS_CONFIG:
    RMAE_WEIGHT: 1.0                    # R-MAE occupancy loss ê°€ì¤‘ì¹˜
    TEACHER_STUDENT_WEIGHT: 0.0         # Phase 1ì—ì„œëŠ” ë¹„í™œì„±í™” (Phase 2ì—ì„œ 0.6ìœ¼ë¡œ ì„¤ì • ì˜ˆì •)

OPTIMIZATION:
    # ===== ğŸ“Š ê¸°ì¡´ R-MAE ìµœì í™” ì„¤ì • ì™„ì „ ë³µì‚¬ =====
    BATCH_SIZE_PER_GPU: 8               # ê¸°ì¡´ê³¼ ë™ì¼
    NUM_EPOCHS: 30                       # ê¸°ì¡´ê³¼ ë™ì¼

    OPTIMIZER: adam_onecycle             # ê¸°ì¡´ê³¼ ë™ì¼
    LR: 0.001                            # ê¸°ì¡´ê³¼ ë™ì¼ (Pretrainingìš© ë‚®ì€ í•™ìŠµë¥ )
    WEIGHT_DECAY: 0.01                   # ê¸°ì¡´ê³¼ ë™ì¼
    MOMENTUM: 0.9                        # ê¸°ì¡´ê³¼ ë™ì¼

    MOMS: [0.95, 0.85]                   # ê¸°ì¡´ê³¼ ë™ì¼
    PCT_START: 0.4                       # ê¸°ì¡´ê³¼ ë™ì¼
    DIV_FACTOR: 10                       # ê¸°ì¡´ê³¼ ë™ì¼
    DECAY_STEP_LIST: [20, 25]            # ê¸°ì¡´ê³¼ ë™ì¼ (30 epochsì— ë§ê²Œ ì¡°ì •)
    LR_DECAY: 0.1                        # ê¸°ì¡´ê³¼ ë™ì¼
    LR_CLIP: 0.0000001                   # ê¸°ì¡´ê³¼ ë™ì¼

    # Warmup ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
    LR_WARMUP: False                     # ê¸°ì¡´ê³¼ ë™ì¼
    WARMUP_EPOCH: 1                      # ê¸°ì¡´ê³¼ ë™ì¼
    
    GRAD_NORM_CLIP: 10                   # ê¸°ì¡´ê³¼ ë™ì¼

# ===== ğŸ“ Phase 1 ì‹¤í—˜ íƒœê·¸ =====
EXPERIMENT:
    PHASE: 1
    DESCRIPTION: 'Teacher-Student architecture baseline with exact R-MAE compatibility'
    FEATURES: ['teacher_student_architecture', 'rmae_full_compatibility']
    EXPECTED_IMPROVEMENT: 'Infrastructure for Phase 2 while maintaining R-MAE performance'