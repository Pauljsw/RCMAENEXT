# tools/cfgs/custom_models/rmae_cmae_voxelnext_pretraining.yaml
# 기존 성공한 rmae_voxelnext_isarc_4class_pretraining.yaml을 기반으로 CMAE 요소 추가

CLASS_NAMES: ['dumptruck', 'excavator', 'grader', 'roller']

DATA_CONFIG:
    _BASE_CONFIG_: cfgs/dataset_configs/custom_dataset_isarc.yaml
    
    # ✅ 기존 성공 로직: 동일한 데이터 증강 설정
    DATA_AUGMENTOR:
        DISABLE_AUG_LIST: ['gt_sampling']
        AUG_CONFIG_LIST:
            - NAME: random_world_flip
              ALONG_AXIS_LIST: ['x']
            - NAME: random_world_scaling
              WORLD_SCALE_RANGE: [0.98, 1.02]

MODEL:
    NAME: RMAECMAEVoxelNeXt  # ➕ 새로운 통합 모델명
    
    # ➕ CMAE-3D 손실 가중치 (논문 기반)
    OCCUPANCY_WEIGHT: 1.0     # R-MAE occupancy loss
    CONTRASTIVE_WEIGHT: 0.6   # CMAE contrastive loss (λ=0.6 optimal)
    FEATURE_WEIGHT: 0.5       # CMAE feature reconstruction loss
    
    # ➕ CMAE-3D 논문 파라미터
    TEMPERATURE: 0.1          # Contrastive learning temperature
    
    VFE:
        NAME: MeanVFE

    BACKBONE_3D:
        NAME: RMAECMAEBackbone  # ➕ 새로운 통합 백본명
        
        # ✅ 기존 성공 R-MAE 파라미터 그대로
        MASKED_RATIO: 0.8
        ANGULAR_RANGE: 1
        PRETRAINING: True
        
        # ➕ CMAE-3D 새 파라미터 (논문 기반)
        MOMENTUM: 0.999          # Teacher EMA momentum
        TEMPERATURE: 0.2         # Contrastive learning temperature

    # ✅ 기존 성공 로직: DENSE_HEAD 섹션 완전 제거 (pretraining에서는 불필요)

    POST_PROCESSING:
        RECALL_THRESH_LIST: [0.3, 0.5, 0.7]
        EVAL_METRIC: kitti

OPTIMIZATION:
    # ✅ 기존 성공 설정 그대로 (잘 작동했던 설정)
    BATCH_SIZE_PER_GPU: 8
    NUM_EPOCHS: 30

    OPTIMIZER: adam_onecycle
    LR: 0.001                 # ✅ Pretraining용 낮은 학습률
    WEIGHT_DECAY: 0.01
    MOMENTUM: 0.9

    MOMS: [0.95, 0.85]
    PCT_START: 0.4
    DIV_FACTOR: 10
    DECAY_STEP_LIST: [20, 25]  # ✅ 30 epoch에 맞게 조정
    LR_DECAY: 0.1
    LR_CLIP: 0.0000001

    LR_WARMUP: False
    WARMUP_EPOCH: 1

    GRAD_NORM_CLIP: 10