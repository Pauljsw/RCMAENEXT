"""
pcdet/models/detectors/cmae_voxelnext_complete.py

âœ… R-MAE + CMAE-3D VoxelNeXt Detector ì™„ì „ êµ¬í˜„
- ê¸°ì¡´ ì„±ê³µí•œ R-MAE ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ CMAE-3D ìš”ì†Œë¥¼ ì ì§„ì ìœ¼ë¡œ ì¶”ê°€
- ì•ˆì •ì ì¸ pretrainingê³¼ fine-tuning ì§€ì›
- ì™„ë²½í•œ ì†ì‹¤ í•¨ìˆ˜ í†µí•©
"""

import torch
import torch.nn.functional as F
from .detector3d_template import Detector3DTemplate


class RMAECMAEVoxelNeXt(Detector3DTemplate):
    """
    âœ… R-MAE + CMAE-3D VoxelNeXt Detector
    
    ê¸°ì¡´ ì„±ê³µí•œ R-MAE ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ CMAE-3D ìš”ì†Œë¥¼ ì ì§„ì ìœ¼ë¡œ ì¶”ê°€:
    1. âœ… R-MAE occupancy prediction (ê¸°ì¡´ ì„±ê³µ ë¡œì§)
    2. â• Multi-scale feature reconstruction (CMAE-3D MLFR)
    3. â• Hierarchical contrastive learning (CMAE-3D HRCL)
    4. â• Teacher-Student momentum update (CMAE-3D)
    """
    
    def __init__(self, model_cfg, num_class, dataset):
        super().__init__(model_cfg=model_cfg, num_class=num_class, dataset=dataset)
        self.module_list = self.build_networks()
        
        # âœ… CMAE-3D ì†ì‹¤ ê°€ì¤‘ì¹˜ (ë…¼ë¬¸ ê¸°ë°˜)
        self.occupancy_weight = model_cfg.get('OCCUPANCY_WEIGHT', 1.0)       # R-MAE loss
        self.contrastive_weight = model_cfg.get('CONTRASTIVE_WEIGHT', 0.6)   # HRCL loss (Î»=0.6 ìµœì )
        self.feature_weight = model_cfg.get('FEATURE_WEIGHT', 0.5)           # MLFR loss
        
        # âœ… CMAE-3D íŒŒë¼ë¯¸í„°
        self.temperature = model_cfg.get('TEMPERATURE', 0.2)
        
        print(f"ğŸ¯ R-MAE + CMAE-3D Detector ì´ˆê¸°í™”")
        print(f"   - Occupancy weight: {self.occupancy_weight}")
        print(f"   - Contrastive weight: {self.contrastive_weight}")
        print(f"   - Feature weight: {self.feature_weight}")
        print(f"   - Temperature: {self.temperature}")
    
    def forward(self, batch_dict):
        """
        âœ… í†µí•© forward í•¨ìˆ˜
        - Pretraining: R-MAE + CMAE-3D ì†ì‹¤
        - Fine-tuning/Inference: í‘œì¤€ detection
        """
        # âœ… Pretraining mode
        if self.training and self._is_pretraining_mode():
            return self._forward_pretraining(batch_dict)
        
        # âœ… Fine-tuning/Inference mode
        else:
            return self._forward_detection(batch_dict)
    
    def _is_pretraining_mode(self):
        """Pretraining ëª¨ë“œ í™•ì¸"""
        # Backboneì—ì„œ PRETRAINING í”Œë˜ê·¸ í™•ì¸
        backbone_cfg = getattr(self.model_cfg, 'BACKBONE_3D', {})
        return backbone_cfg.get('PRETRAINING', False)
    
    def _forward_pretraining(self, batch_dict):
        """
        âœ… Pretraining forward - R-MAE + CMAE-3D í†µí•© ì†ì‹¤
        """
        # âœ… 1. ëª¨ë“  ëª¨ë“ˆ ì‹¤í–‰ (ê¸°ì¡´ ì„±ê³µ ë¡œì§ì˜ í•µì‹¬!)
        for cur_module in self.module_list:
            batch_dict = cur_module(batch_dict)
        
        # âœ… 2. í†µí•© ì†ì‹¤ ê³„ì‚°
        loss_dict = self._compute_pretraining_losses(batch_dict)
        
        # âœ… 3. ì´ ì†ì‹¤ ë° ë””ë²„ê¹… ì •ë³´
        total_loss = sum(loss_dict.values())
        
        ret_dict = {
            'loss': total_loss,
            **loss_dict,
            'tb_dict': self._get_tb_dict(loss_dict, total_loss),
            'disp_dict': self._get_disp_dict(loss_dict, total_loss)
        }
        
        return ret_dict
    
    def _forward_detection(self, batch_dict):
        """
        âœ… Fine-tuning/Inference forward - í‘œì¤€ detection
        """
        # í‘œì¤€ detection pipeline
        for cur_module in self.module_list:
            batch_dict = cur_module(batch_dict)
        
        if self.training:
            # Fine-tuning mode: detection loss
            loss, tb_dict, disp_dict = self.get_training_loss()
            ret_dict = {
                'loss': loss, 'tb_dict': tb_dict, 'disp_dict': disp_dict
            }
        else:
            # Inference mode: predictions
            pred_dicts, recall_dicts = self.post_processing(batch_dict)
            ret_dict = {
                'pred_dicts': pred_dicts, 'recall_dicts': recall_dicts
            }
        
        return ret_dict
    
    def _compute_pretraining_losses(self, batch_dict):
        """
        âœ… Pretraining ì†ì‹¤ í•¨ìˆ˜ í†µí•© ê³„ì‚°
        
        ë…¼ë¬¸ ìˆ˜ì‹ (17): L_total = L_MLFR + Î»L_HRCL
        + R-MAE occupancy loss
        """
        loss_dict = {}
        device = next(self.parameters()).device
        
        # âœ… 1. R-MAE Occupancy Prediction Loss (ê¸°ì¡´ ì„±ê³µ ë¡œì§)
        occupancy_loss = self._compute_occupancy_loss(batch_dict)
        loss_dict['occupancy_loss'] = occupancy_loss * self.occupancy_weight
        
        # âœ… 2. CMAE-3D Multi-scale Latent Feature Reconstruction (MLFR)
        mlfr_loss = batch_dict.get('mlfr_loss', torch.tensor(0.1, device=device, requires_grad=True))
        loss_dict['mlfr_loss'] = mlfr_loss * self.feature_weight
        
        # âœ… 3. CMAE-3D Hierarchical Relational Contrastive Learning (HRCL)
        hrcl_loss = batch_dict.get('hrcl_loss', torch.tensor(0.1, device=device, requires_grad=True))
        loss_dict['hrcl_loss'] = hrcl_loss * self.contrastive_weight
        
        # âœ… 4. ì¶”ê°€ contrastive loss components
        voxel_contrastive = batch_dict.get('voxel_contrastive_loss', torch.tensor(0.0, device=device))
        frame_contrastive = batch_dict.get('frame_contrastive_loss', torch.tensor(0.0, device=device))
        
        loss_dict['voxel_contrastive_loss'] = voxel_contrastive * 0.1  # ë³´ì¡° ì†ì‹¤
        loss_dict['frame_contrastive_loss'] = frame_contrastive * 0.1  # ë³´ì¡° ì†ì‹¤
        
        return loss_dict
    
    def _compute_occupancy_loss(self, batch_dict):
        """
        âœ… R-MAE Occupancy Prediction Loss (ê¸°ì¡´ ì„±ê³µ ë¡œì§)
        """
        device = next(self.parameters()).device
        
        occupancy_pred = batch_dict.get('occupancy_pred', None)
        occupancy_coords = batch_dict.get('occupancy_coords', None)
        
        if occupancy_pred is None or occupancy_coords is None:
            return torch.tensor(0.1, device=device, requires_grad=True)
        
        try:
            # âœ… ê¸°ì¡´ ì„±ê³µ occupancy loss ë¡œì§
            # Binary occupancy target (1 for occupied voxels)
            occupancy_target = torch.ones_like(occupancy_pred)
            
            # Binary cross-entropy loss with logits
            occupancy_loss = F.binary_cross_entropy_with_logits(
                occupancy_pred, occupancy_target, reduction='mean'
            )
            
            return occupancy_loss
            
        except Exception as e:
            print(f"âš ï¸ Occupancy loss computation error: {e}")
            return torch.tensor(0.1, device=device, requires_grad=True)
    
    def _get_tb_dict(self, loss_dict, total_loss):
        """TensorBoard ë¡œê¹…ìš© ë”•ì…”ë„ˆë¦¬"""
        tb_dict = {
            'total_loss': total_loss.item(),
        }
        
        for key, value in loss_dict.items():
            if isinstance(value, torch.Tensor):
                tb_dict[key] = value.item()
            else:
                tb_dict[key] = value
        
        return tb_dict
    
    def _get_disp_dict(self, loss_dict, total_loss):
        """í™”ë©´ ì¶œë ¥ìš© ë”•ì…”ë„ˆë¦¬"""
        disp_dict = {
            'loss': f'{total_loss.item():.4f}',
        }
        
        for key, value in loss_dict.items():
            if isinstance(value, torch.Tensor):
                disp_dict[key] = f'{value.item():.4f}'
            else:
                disp_dict[key] = f'{value:.4f}'
        
        return disp_dict


class CMAEVoxelNeXt(RMAECMAEVoxelNeXt):
    """âœ… í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­ í´ë˜ìŠ¤"""
    pass


class RMAEVoxelNeXt(RMAECMAEVoxelNeXt):
    """âœ… R-MAE ì „ìš© ë²„ì „ (ê¸°ì¡´ í˜¸í™˜ì„±)"""
    
    def __init__(self, model_cfg, num_class, dataset):
        super().__init__(model_cfg, num_class, dataset)
        
        # R-MAE ì „ìš© ì„¤ì •
        self.contrastive_weight = 0.0  # CMAE ë¹„í™œì„±í™”
        self.feature_weight = 0.0      # MLFR ë¹„í™œì„±í™”
        
        print("ğŸ¯ R-MAE ì „ìš© ëª¨ë“œ (CMAE ê¸°ëŠ¥ ë¹„í™œì„±í™”)")
    
    def _compute_pretraining_losses(self, batch_dict):
        """R-MAE ì „ìš© ì†ì‹¤ (occupancyë§Œ)"""
        loss_dict = {}
        
        # R-MAE Occupancy Lossë§Œ ì‚¬ìš©
        occupancy_loss = self._compute_occupancy_loss(batch_dict)
        loss_dict['occupancy_loss'] = occupancy_loss * self.occupancy_weight
        
        return loss_dict