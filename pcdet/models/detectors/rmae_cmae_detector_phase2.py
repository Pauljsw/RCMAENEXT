# pcdet/models/detectors/rmae_cmae_detector_phase2.py
"""
CMAE-3D Phase 2: Multi-scale Latent Feature Reconstruction Detector

Phase 1 ê¸°ëŠ¥ + Phase 2 MLFR ì¶”ê°€:
- Teacher-Student loss ê´€ë¦¬ (Phase 1)
- Multi-scale Feature Reconstruction loss ì¶”ê°€ (Phase 2)
- í†µí•© loss balancing
"""

import torch
import torch.nn.functional as F
from .rmae_cmae_detector_phase1 import RMAECMAEDetectorPhase1


class RMAECMAEDetectorPhase2(RMAECMAEDetectorPhase1):
    """
    ğŸ”¥ Phase 2: Multi-scale Latent Feature Reconstruction Detector
    
    Phase 1 ê¸°ëŠ¥ ì™„ì „ ìœ ì§€ + CMAE-3D MLFR ì¶”ê°€:
    
    Phase 1 (ê¸°ì¡´):
    - Teacher-Student Architecture âœ…
    - R-MAE loss management âœ…
    - Detection loss âœ…
    
    Phase 2 (ìƒˆë¡œ ì¶”ê°€):
    - Multi-scale Latent Feature Reconstruction loss ğŸ”¥
    - Enhanced loss balancing ğŸ”¥
    - Performance monitoring ğŸ”¥
    """
    
    def __init__(self, model_cfg, num_class, dataset):
        super().__init__(model_cfg=model_cfg, num_class=num_class, dataset=dataset)
        
        # Phase 2 MLFR ì„¤ì •
        self.enable_mlfr = getattr(model_cfg.BACKBONE_3D, 'ENABLE_MLFR', True)
        
        # ğŸ“ Phase 2 Voxel Contrastive Learning ì„¤ì •
        self.enable_voxel_contrastive = getattr(model_cfg.BACKBONE_3D, 'ENABLE_VOXEL_CONTRASTIVE', True)
        
        self.phase2_loss_weights = {
            'rmae_weight': model_cfg.get('RMAE_WEIGHT', 1.0),                    # R-MAE occupancy
            'mlfr_weight': model_cfg.get('MLFR_WEIGHT', 1.0),                    # Multi-scale reconstruction  
            'voxel_contrastive_weight': model_cfg.get('VOXEL_CONTRASTIVE_WEIGHT', 0.6),  # Voxel contrastive (CMAE-3D paper)
            'teacher_student_weight': model_cfg.get('TEACHER_STUDENT_WEIGHT', 0.0),     # Phase 3ì—ì„œ í™œì„±í™” ì˜ˆì •
            'detection_weight': model_cfg.get('DETECTION_WEIGHT', 1.0)          # Detection loss
        }
        
        # Loss storage
        self.forward_ret_dict = {}
        
        print(f"ğŸš€ Phase 2 Detector initialized:")
        print(f"   - Phase 1 features: âœ… Teacher-Student, R-MAE, Detection")
        print(f"   - Phase 2 features: {'âœ…' if self.enable_mlfr else 'âŒ'} MLFR, {'âœ…' if self.enable_voxel_contrastive else 'âŒ'} Voxel Contrastive")
        print(f"   - Loss weights: {self.phase2_loss_weights}")
    
    def forward(self, batch_dict):
        """
        Phase 2 Forward:
        1. ëª¨ë“  ëª¨ë“ˆ ìˆœì°¨ ì‹¤í–‰ (Phase 1ê³¼ ë™ì¼)
        2. MLFR features ì €ì¥ ë° ê´€ë¦¬ (Phase 2 ì¶”ê°€)
        3. Enhanced loss ê³„ì‚°
        """
        
        # ê¸°ì¡´ ëª¨ë“ˆ ìˆœì°¨ ì‹¤í–‰ (Phase 1ê³¼ ë™ì¼)
        for cur_module in self.module_list:
            batch_dict = cur_module(batch_dict)
        
        # Training modeì—ì„œë§Œ loss ê³„ì‚°
        if self.training:
            loss, tb_dict, disp_dict = self.get_training_loss()
            
            ret_dict = {
                'loss': loss
            }
            return ret_dict, tb_dict, disp_dict
        else:
            # Inference mode (Phase 1ê³¼ ë™ì¼)
            pred_dicts, recall_dicts = self.post_processing(batch_dict)
            return pred_dicts, recall_dicts
    
    def get_training_loss(self):
        """
        Phase 2 Training Loss:
        1. R-MAE occupancy loss (Phase 1) âœ…
        2. Multi-scale feature reconstruction loss (Phase 2) ğŸ”¥
        3. Voxel-level contrastive learning loss (Phase 2) ğŸ”¥
        4. Detection loss (fine-tuning ì‹œ) âœ…
        5. Teacher-Student contrastive loss (Phase 3ì—ì„œ ì¶”ê°€ ì˜ˆì •) ğŸ”„
        """
        disp_dict = {}
        loss = 0
        
        # ğŸ“ 1. R-MAE Occupancy Loss (Phase 1 ìœ ì§€)
        rmae_loss, rmae_tb_dict = self._get_rmae_loss()
        weighted_rmae_loss = self.phase2_loss_weights['rmae_weight'] * rmae_loss
        loss += weighted_rmae_loss
        disp_dict.update(rmae_tb_dict)
        
        # ğŸ“ 2. Multi-scale Latent Feature Reconstruction Loss (Phase 2)
        mlfr_loss, mlfr_tb_dict = self._get_mlfr_loss()
        weighted_mlfr_loss = self.phase2_loss_weights['mlfr_weight'] * mlfr_loss
        loss += weighted_mlfr_loss
        disp_dict.update(mlfr_tb_dict)
        
        # ğŸ“ 3. Voxel-level Contrastive Learning Loss (Phase 2 ìƒˆë¡œ ì¶”ê°€)
        voxel_contrastive_loss, voxel_contrastive_tb_dict = self._get_voxel_contrastive_loss()
        weighted_voxel_contrastive_loss = self.phase2_loss_weights['voxel_contrastive_weight'] * voxel_contrastive_loss
        loss += weighted_voxel_contrastive_loss
        disp_dict.update(voxel_contrastive_tb_dict)
        
        # ğŸ“ 4. Detection Loss (Fine-tuning ì‹œ)
        if not self._is_pretraining_mode():
            det_loss, det_tb_dict = self._get_detection_loss()
            weighted_det_loss = self.phase2_loss_weights['detection_weight'] * det_loss
            loss += weighted_det_loss
            disp_dict.update(det_tb_dict)
        
        # ğŸ“ 5. Teacher-Student Contrastive Loss (Phase 2ì—ì„œëŠ” ì•„ì§ ë¹„í™œì„±í™”)
        if self.enable_teacher_student and self.phase2_loss_weights['teacher_student_weight'] > 0:
            ts_loss, ts_tb_dict = self._get_teacher_student_loss()
            weighted_ts_loss = self.phase2_loss_weights['teacher_student_weight'] * ts_loss
            loss += weighted_ts_loss
            disp_dict.update(ts_tb_dict)
        
        # ğŸ“ 6. Phase 2 í†µí•© ì •ë³´
        disp_dict.update({
            'total_loss': loss.item(),
            'rmae_loss': rmae_loss.item(),
            'mlfr_loss': mlfr_loss.item(),
            'voxel_contrastive_loss': voxel_contrastive_loss.item(),
            'weighted_rmae': weighted_rmae_loss.item(),
            'weighted_mlfr': weighted_mlfr_loss.item(),
            'weighted_voxel_contrastive': weighted_voxel_contrastive_loss.item(),
            'phase2_active': True,
            'mlfr_enabled': self.enable_mlfr,
            'voxel_contrastive_enabled': self.enable_voxel_contrastive
        })
        
        # Tensorboard loggingì„ ìœ„í•œ tb_dict
        tb_dict = {
            'loss': loss.item(),
            'phase2_total_loss': loss.item(),
            'phase2_rmae_loss': rmae_loss.item(),
            'phase2_mlfr_loss': mlfr_loss.item(),
            'phase2_voxel_contrastive_loss': voxel_contrastive_loss.item(),
            'phase2_rmae_weighted': weighted_rmae_loss.item(),
            'phase2_mlfr_weighted': weighted_mlfr_loss.item(),
            'phase2_voxel_contrastive_weighted': weighted_voxel_contrastive_loss.item(),
            **disp_dict
        }
        
        return loss, tb_dict, disp_dict
    
    def _get_mlfr_loss(self):
        """
        ğŸ“ Phase 2: Multi-scale Latent Feature Reconstruction Loss
        
        Backboneì—ì„œ ê³„ì‚°ëœ MLFR lossë¥¼ ê°€ì ¸ì™€ì„œ detector levelì—ì„œ í†µí•© ê´€ë¦¬
        """
        tb_dict = {}
        
        # Backbone moduleì—ì„œ MLFR loss ê°€ì ¸ì˜¤ê¸°
        backbone_module = self._get_backbone_module()
        
        if backbone_module is not None and hasattr(backbone_module, 'get_loss'):
            # Backboneì˜ get_lossì—ì„œ MLFR loss í¬í•¨ëœ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            total_backbone_loss, backbone_tb_dict = backbone_module.get_loss()
            
            # MLFR ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
            mlfr_loss = backbone_tb_dict.get('mlfr_total_loss', 0.0)
            
            # Scaleë³„ MLFR loss ì •ë³´ ì¶”ê°€
            for key, value in backbone_tb_dict.items():
                if 'mlfr' in key:
                    tb_dict[key] = value
            
            # MLFR í™œì„±í™” ìƒíƒœ ê¸°ë¡
            tb_dict['mlfr_backbone_enabled'] = backbone_tb_dict.get('phase2_mlfr', False)
            
            return torch.tensor(mlfr_loss, device='cuda', requires_grad=True), tb_dict
            
        else:
            # Backboneì—ì„œ MLFR lossë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ëŠ” ê²½ìš°
            tb_dict['mlfr_error'] = 'backbone_not_found'
            return torch.tensor(0.0, device='cuda', requires_grad=True), tb_dict
    
    def _get_backbone_module(self):
        """Backbone module ì°¾ê¸°"""
        for module in self.module_list:
            if hasattr(module, '__class__') and 'Backbone' in module.__class__.__name__:
                return module
        return None
    
    def _get_voxel_contrastive_loss(self):
        """
        ğŸ“ Phase 2: Voxel-level Contrastive Learning Loss
        
        Backboneì—ì„œ ê³„ì‚°ëœ voxel contrastive lossë¥¼ ê°€ì ¸ì™€ì„œ detector levelì—ì„œ í†µí•© ê´€ë¦¬
        """
        tb_dict = {}
        
        # Backbone moduleì—ì„œ voxel contrastive loss ê°€ì ¸ì˜¤ê¸°
        backbone_module = self._get_backbone_module()
        
        if backbone_module is not None and hasattr(backbone_module, 'get_loss'):
            # Backboneì˜ get_lossì—ì„œ voxel contrastive loss í¬í•¨ëœ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            total_backbone_loss, backbone_tb_dict = backbone_module.get_loss()
            
            # Voxel contrastive ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
            voxel_contrastive_loss = backbone_tb_dict.get('phase2_voxel_contrastive_loss', 0.0)
            
            # Voxel contrastive statistics ì¶”ê°€
            for key, value in backbone_tb_dict.items():
                if 'voxel_contrastive' in key or 'voxel_positive' in key or 'voxel_negative' in key or 'voxel_avg' in key:
                    tb_dict[key] = value
            
            # Voxel contrastive í™œì„±í™” ìƒíƒœ ê¸°ë¡
            tb_dict['voxel_contrastive_backbone_enabled'] = backbone_tb_dict.get('phase2_voxel_contrastive', False)
            
            return torch.tensor(voxel_contrastive_loss, device='cuda', requires_grad=True), tb_dict
            
        else:
            # Backboneì—ì„œ voxel contrastive lossë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ëŠ” ê²½ìš°
            tb_dict['voxel_contrastive_error'] = 'backbone_not_found'
            return torch.tensor(0.0, device='cuda', requires_grad=True), tb_dict
    
    def _get_rmae_loss(self):
        """Phase 1 R-MAE occupancy loss (ë™ì¼)"""
        tb_dict = {}
        
        # Backboneì—ì„œ R-MAE loss ê°€ì ¸ì˜¤ê¸°  
        backbone_module = self._get_backbone_module()
        
        if backbone_module is not None and hasattr(backbone_module, 'get_loss'):
            total_backbone_loss, backbone_tb_dict = backbone_module.get_loss()
            
            # R-MAE ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
            rmae_loss = backbone_tb_dict.get('phase2_rmae_loss', 0.0)
            
            # R-MAE ê´€ë ¨ tb_dict ì¶”ê°€
            for key, value in backbone_tb_dict.items():
                if 'rmae' in key or 'occupancy' in key:
                    tb_dict[key] = value
                    
            return torch.tensor(rmae_loss, device='cuda', requires_grad=True), tb_dict
        else:
            return torch.tensor(0.0, device='cuda', requires_grad=True), tb_dict
    
    def _get_detection_loss(self):
        """í‘œì¤€ detection loss (Phase 1ê³¼ ë™ì¼)"""
        tb_dict = {}
        loss = 0
        
        # Dense headì—ì„œ loss ê³„ì‚°
        for module in self.module_list:
            if hasattr(module, '__class__') and 'Head' in module.__class__.__name__:
                if hasattr(module, 'get_loss'):
                    head_loss, head_tb_dict = module.get_loss()
                    loss += head_loss
                    tb_dict.update(head_tb_dict)
        
        return loss, tb_dict
    
    def _get_teacher_student_loss(self):
        """
        Teacher-Student contrastive loss
        Phase 2ì—ì„œëŠ” ì—¬ì „íˆ placeholder (Phase 3ì—ì„œ êµ¬í˜„ ì˜ˆì •)
        """
        tb_dict = {
            'teacher_student_loss': 0.0,
            'phase2_ts_placeholder': True,
            'phase3_preview': 'contrastive_learning_coming_soon'
        }
        
        # Phase 3ì—ì„œ ì—¬ê¸°ì— ì‹¤ì œ contrastive loss êµ¬í˜„ ì˜ˆì •
        loss = torch.tensor(0.0, device='cuda', requires_grad=True)
        
        return loss, tb_dict
    
    def _is_pretraining_mode(self):
        """í˜„ì¬ pretraining ëª¨ë“œì¸ì§€ í™•ì¸"""
        backbone_module = self._get_backbone_module()
        if backbone_module and hasattr(backbone_module, 'model_cfg') and hasattr(backbone_module.model_cfg, 'PRETRAINING'):
            return backbone_module.model_cfg.PRETRAINING
        return False
    
    def get_phase2_status(self):
        """Phase 2 ìƒíƒœ ì •ë³´ ë°˜í™˜ (debuggingìš©)"""
        return {
            'phase2_enabled': True,
            'mlfr_enabled': self.enable_mlfr,
            'voxel_contrastive_enabled': self.enable_voxel_contrastive,
            'loss_weights': self.phase2_loss_weights,
            'backbone_type': type(self._get_backbone_module()).__name__ if self._get_backbone_module() else 'Unknown'
        }
    
    def get_mlfr_features(self):
        """MLFR features ì ‘ê·¼ìš© ë©”ì„œë“œ (Phase 3 ì¤€ë¹„)"""
        features = {}
        
        backbone_module = self._get_backbone_module()
        if backbone_module and hasattr(backbone_module, 'forward_ret_dict'):
            ret_dict = backbone_module.forward_ret_dict
            if 'mlfr_results' in ret_dict:
                features['mlfr_results'] = ret_dict['mlfr_results']
            if 'teacher_features' in ret_dict:
                features['teacher_features'] = ret_dict['teacher_features']
            if 'student_multiscale_features' in ret_dict:
                features['student_multiscale_features'] = ret_dict['student_multiscale_features']
            if 'voxel_contrastive_results' in ret_dict:
                features['voxel_contrastive_results'] = ret_dict['voxel_contrastive_results']
        
        return features