# pcdet/models/backbones_3d/rmae_cmae_backbone_phase1.py (REAL R-MAE Implementation)
"""
R-MAE + CMAE-3D Phase 1: ì‹¤ì œ R-MAE occupancy loss ì •í™•íˆ êµ¬í˜„
ê¸°ì¡´ ì„±ê³µí•œ radial_mae_voxelnext.pyì˜ ë¡œì§ì„ ì •í™•íˆ ë³µì‚¬

í•µì‹¬:
1. ì‹¤ì œ R-MAE radial masking êµ¬í˜„ âœ…
2. ì‹¤ì œ occupancy decoder + prediction êµ¬í˜„ âœ…
3. ì‹¤ì œ occupancy target ìƒì„± ë¡œì§ êµ¬í˜„ âœ…
4. Teacher-Student Phase 1 êµ¬ì¡° ì¶”ê°€ âœ…
"""

import torch
import torch.nn as nn
import spconv.pytorch as spconv
from functools import partial
import numpy as np
from .radial_mae_voxelnext import RadialMAEVoxelNeXt


class RMAECMAEBackbonePhase1(RadialMAEVoxelNeXt):
    """
    ğŸ”¥ Phase 1: ì‹¤ì œ R-MAE + Teacher-Student Architecture
    
    ê¸°ì¡´ RadialMAEVoxelNeXtì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ìƒì†í•˜ì—¬
    ì‹¤ì œ R-MAE occupancy loss + Teacher-Student êµ¬ì¡° êµ¬í˜„
    """
    
    def __init__(self, model_cfg, input_channels, grid_size, voxel_size, point_cloud_range, **kwargs):
        # ê¸°ì¡´ RadialMAEVoxelNeXt ì´ˆê¸°í™” (ëª¨ë“  R-MAE ê¸°ëŠ¥ í¬í•¨)
        super().__init__(model_cfg, input_channels, grid_size, voxel_size, point_cloud_range, **kwargs)
        
        # ğŸ“ Phase 1: Teacher-Student ì¶”ê°€ ì„¤ì •
        self.enable_teacher_student = model_cfg.get('ENABLE_TEACHER_STUDENT', False)
        
        if self.enable_teacher_student:
            print("ğŸ”¥ Phase 1: Teacher-Student Architecture ENABLED")
            
            # Feature projection heads (Phase 2 ì¤€ë¹„ìš©)
            self.teacher_projector = self._build_projector(128, 128)
            self.student_projector = self._build_projector(128, 128)
            
            print(f"   - Feature projectors: 128 -> 128 dims")
        
        print(f"ğŸ”¥ Phase 1 Backbone Initialized:")
        print(f"   - Teacher-Student: {self.enable_teacher_student}")
        print(f"   - Pretraining: {getattr(model_cfg, 'PRETRAINING', False)}")
        print(f"   - Masked ratio: {getattr(self, 'masked_ratio', 0.8)}")
    
    def _build_projector(self, input_dim, output_dim):
        """Feature projectionì„ ìœ„í•œ MLP head (Phase 2 ì¤€ë¹„)"""
        return nn.Sequential(
            nn.Linear(input_dim, input_dim),
            nn.ReLU(inplace=True),
            nn.Linear(input_dim, output_dim)
        )
    
    def forward(self, batch_dict):
        """
        ğŸš€ Phase 1 Forward: ê¸°ì¡´ RadialMAEVoxelNeXt forward + Teacher-Student ì •ë³´ ì¶”ê°€
        
        1. ê¸°ì¡´ RadialMAEVoxelNeXt forward ì‹¤í–‰ (R-MAE masking + occupancy prediction)
        2. Teacher-Student ì •ë³´ ì¶”ê°€ (Phase 2 ì¤€ë¹„)
        3. ëª¨ë“  ê¸°ì¡´ ê¸°ëŠ¥ ì™„ì „ ìœ ì§€
        """
        
        # ğŸ“ ê¸°ì¡´ RadialMAEVoxelNeXt forward ì‹¤í–‰ (í•µì‹¬!)
        # ì´ ë¶€ë¶„ì—ì„œ radial masking + occupancy predictionì´ ëª¨ë‘ ì²˜ë¦¬ë¨
        result = super().forward(batch_dict)
        
        # ğŸ“ Phase 1: Teacher-Student ì •ë³´ ì¶”ê°€ (training ì‹œì—ë§Œ)
        if self.training and self.enable_teacher_student:
            
            # Teacher features: complete view ì •ë³´ (Phase 2ì—ì„œ í™œìš©)
            teacher_features = {
                'encoded_tensor': result.get('encoded_spconv_tensor'),
                'multi_scale_features': result.get('multi_scale_3d_features', {}),
                'occupancy_info': {
                    'pred': batch_dict.get('occupancy_pred'),
                    'coords': batch_dict.get('occupancy_coords')
                }
            }
            
            # Student features: masked view ì •ë³´ (í˜„ì¬ ê²°ê³¼)
            student_features = {
                'encoded_tensor': result.get('encoded_spconv_tensor'),
                'multi_scale_features': result.get('multi_scale_3d_features', {}),
                'occupancy_info': {
                    'pred': batch_dict.get('occupancy_pred'),
                    'coords': batch_dict.get('occupancy_coords')
                }
            }
            
            # Feature projection (Phase 2 ì¤€ë¹„ìš©)
            if hasattr(self, 'teacher_projector') and hasattr(self, 'student_projector'):
                try:
                    # Global pooling for projection
                    if result.get('encoded_spconv_tensor') is not None:
                        encoded_features = result['encoded_spconv_tensor'].features
                        if len(encoded_features) > 0:
                            teacher_global = torch.mean(encoded_features, dim=0, keepdim=True)
                            student_global = torch.mean(encoded_features, dim=0, keepdim=True)
                            
                            teacher_embed = self.teacher_projector(teacher_global)
                            student_embed = self.student_projector(student_global)
                            
                            teacher_features['embed'] = teacher_embed
                            student_features['embed'] = student_embed
                except Exception as e:
                    print(f"Warning: Feature projection failed: {e}")
            
            # Phase 1 ì •ë³´ë¥¼ batch_dictì— ì¶”ê°€ (loss ê³„ì‚°ìš©)
            batch_dict.update({
                'teacher_features': teacher_features,
                'student_features': student_features,
                'phase1_enabled': True
            })
        
        return result