"""
pcdet/models/backbones_3d/rmae_cmae_backbone.py

R-MAE + CMAE-3D í†µí•© Backbone
- ê¸°ì¡´ ì„±ê³µí•œ R-MAE ë¡œì§ 100% ìœ ì§€ 
- CMAE-3D ë…¼ë¬¸ ë…¼ë¦¬ ì •í™•íˆ êµ¬í˜„ (Sparse CNN ì ì‘)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import spconv.pytorch as spconv
from functools import partial
import numpy as np
from .spconv_backbone_voxelnext import VoxelResBackBone8xVoxelNeXt


class RMAECMAEBackbone(VoxelResBackBone8xVoxelNeXt):
    """
    R-MAE + CMAE-3D Backbone
    
    ë…¼ë¬¸ ë…¼ë¦¬ ìœ ì§€:
    1. âœ… R-MAE radial masking (ê¸°ì¡´ ì„±ê³µ ë¡œì§)
    2. âœ… CMAE-3D Teacher-Student with proper EMA (ë…¼ë¬¸ êµ¬ì¡°)
    3. âœ… Sparse CNN ì ì‘ (Transformer ëŒ€ì‹  VoxelNeXt backbone)
    """
    
    def __init__(self, model_cfg, input_channels, grid_size, voxel_size, point_cloud_range, **kwargs):
        # âœ… ê¸°ì¡´ ì„±ê³µ ë¡œì§: ë¶€ëª¨ í´ë˜ìŠ¤ ì´ˆê¸°í™” (ê¸°ì¡´ VoxelNeXt êµ¬ì¡° ê·¸ëŒ€ë¡œ)
        super().__init__(model_cfg, input_channels, grid_size, **kwargs)
        
        # âœ… ì‹¤ì œ ì†ì„± ì €ì¥ (Teacher êµ¬ì¶•ì— í•„ìš”)
        self.model_cfg = model_cfg
        self.input_channels = input_channels  
        self.grid_size = grid_size
        self.voxel_size = voxel_size
        self.point_cloud_range = point_cloud_range
        
        # âœ… ê¸°ì¡´ ì„±ê³µ ë¡œì§: R-MAE íŒŒë¼ë¯¸í„°
        self.masked_ratio = model_cfg.get('MASKED_RATIO', 0.8)
        self.angular_range = model_cfg.get('ANGULAR_RANGE', 1)
        
        # â• CMAE ìƒˆ íŒŒë¼ë¯¸í„°
        self.momentum = model_cfg.get('MOMENTUM', 0.999)
        self.temperature = model_cfg.get('TEMPERATURE', 0.1)
        
        # âœ… ê¸°ì¡´ ì„±ê³µ ë¡œì§: R-MAE pretrainingìš© decoder
        if hasattr(model_cfg, 'PRETRAINING') and model_cfg.PRETRAINING:
            norm_fn = partial(nn.BatchNorm1d, eps=1e-3, momentum=0.01)
            self.occupancy_decoder = spconv.SparseSequential(
                spconv.SubMConv3d(128, 64, 3, padding=1, bias=False, indice_key='dec1'),
                norm_fn(64), nn.ReLU(),
                spconv.SubMConv3d(64, 32, 3, padding=1, bias=False, indice_key='dec2'),
                norm_fn(32), nn.ReLU(),
                spconv.SubMConv3d(32, 1, 1, bias=True, indice_key='dec_out')
            )
            
            # â• CMAE ìƒˆ ìš”ì†Œ: Teacher network ì¶”ê°€
            self._build_teacher_network()
            
            # â• CMAE ìƒˆ ìš”ì†Œ: Feature projectors ì¶”ê°€
            self._build_feature_projectors()
        
        print(f"ğŸ¯ R-MAE + CMAE Backbone ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   - R-MAE mask ratio: {self.masked_ratio}")
        print(f"   - CMAE momentum: {self.momentum}")
    
    def _build_teacher_network(self):
        """
        â• CMAE Teacher network êµ¬ì¶• (ë…¼ë¬¸ ë…¼ë¦¬ ì¤€ìˆ˜)
        
        CMAE-3D ë…¼ë¬¸:
        - Teacher: full point cloud (unmasked)
        - Student: masked point cloud  
        - TeacherëŠ” Studentì˜ EMA copy
        """
        try:
            print("ğŸ”§ CMAE-3D Teacher network êµ¬ì¶• (ë…¼ë¬¸ ë…¼ë¦¬ ì¤€ìˆ˜)")
            print(f"ğŸ” Teacher íŒŒë¼ë¯¸í„°: input_channels={self.input_channels}, grid_size={self.grid_size}")
            
            # âœ… CMAE-3D ë…¼ë¬¸: TeacherëŠ” Studentì™€ ë™ì¼í•œ êµ¬ì¡°
            # Sparse CNN ì ì‘: VoxelNeXt backbone ì‚¬ìš© (Transformer ëŒ€ì‹ )
            from .spconv_backbone_voxelnext import VoxelResBackBone8xVoxelNeXt
            
            # Teacherìš© ë³„ë„ model_cfg (indice_key ì¶©ëŒ ë°©ì§€)
            teacher_cfg = type('TeacherConfig', (), {})()
            for attr in dir(self.model_cfg):
                if not attr.startswith('_'):
                    setattr(teacher_cfg, attr, getattr(self.model_cfg, attr))
            
            self.teacher_backbone = VoxelResBackBone8xVoxelNeXt(
                model_cfg=teacher_cfg,
                input_channels=self.input_channels, 
                grid_size=self.grid_size
            )
            
            # âœ… CMAE-3D ë…¼ë¬¸: Teacher íŒŒë¼ë¯¸í„°ë¥¼ Studentë¡œ ì´ˆê¸°í™”
            print("ğŸ”„ Teacher íŒŒë¼ë¯¸í„° ì´ˆê¸°í™” (CMAE-3D EMA ë°©ì‹)")
            self._initialize_teacher_from_student()
            
            # TeacherëŠ” gradient ì—…ë°ì´íŠ¸ ì—†ìŒ (EMAë§Œ)
            for param in self.teacher_backbone.parameters():
                param.requires_grad = False
            
            self.has_teacher = True
            print(f"âœ… CMAE-3D Teacher network êµ¬ì¶• ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ Teacher network êµ¬ì¶• ì‹¤íŒ¨: {e}")
            import traceback
            print(f"ğŸ” ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            self.has_teacher = False
    
    def _initialize_teacher_from_student(self):
        """
        CMAE-3D ë…¼ë¬¸: Teacherë¥¼ Student íŒŒë¼ë¯¸í„°ë¡œ ì •í™•íˆ ì´ˆê¸°í™”
        """
        with torch.no_grad():
            # ëª¨ë“  conv ë ˆì´ì–´ ì´ˆê¸°í™”
            teacher_modules = list(self.teacher_backbone.named_modules())
            student_modules = list(self.named_modules())
            
            teacher_dict = {name: module for name, module in teacher_modules}
            student_dict = {name: module for name, module in student_modules}
            
            # conv_input, conv1, conv2, conv3, conv4 ì´ˆê¸°í™”
            layer_names = ['conv_input', 'conv1', 'conv2', 'conv3', 'conv4']
            
            for layer_name in layer_names:
                if layer_name in teacher_dict and layer_name in student_dict:
                    self._copy_layer_parameters(
                        student_dict[layer_name], 
                        teacher_dict[layer_name]
                    )
                    print(f"âœ… Teacher {layer_name} ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _copy_layer_parameters(self, student_layer, teacher_layer):
        """ê°œë³„ ë ˆì´ì–´ íŒŒë¼ë¯¸í„° ë³µì‚¬"""
        student_params = list(student_layer.parameters())
        teacher_params = list(teacher_layer.parameters())
        
        for s_param, t_param in zip(student_params, teacher_params):
            if s_param.shape == t_param.shape:
                t_param.data.copy_(s_param.data)
    
    def _build_feature_projectors(self):
        """
        â• CMAE Feature projectors êµ¬ì¶• (ìƒˆë¡œ ì¶”ê°€)
        Multi-scale featuresë¥¼ ê³µí†µ ì°¨ì›ìœ¼ë¡œ íˆ¬ì˜
        """
        try:
            # ê°„ë‹¨í•œ projection heads
            self.student_projector = nn.Sequential(
                nn.Linear(128, 128),  # VoxelNeXt ë§ˆì§€ë§‰ ì±„ë„
                nn.ReLU(),
                nn.Linear(128, 256)   # ê³µí†µ projection ì°¨ì›
            )
            
            self.teacher_projector = nn.Sequential(
                nn.Linear(128, 128),
                nn.ReLU(), 
                nn.Linear(128, 256)
            )
            
            # Teacher projectorë¥¼ Studentë¡œ ì´ˆê¸°í™”
            with torch.no_grad():
                for teacher_param, student_param in zip(
                    self.teacher_projector.parameters(),
                    self.student_projector.parameters()
                ):
                    teacher_param.copy_(student_param)
                    teacher_param.requires_grad = False
            
            print("âœ… Feature projectors êµ¬ì¶• ì™„ë£Œ")
            
        except Exception as e:
            print(f"âš ï¸ Feature projectors êµ¬ì¶• ì‹¤íŒ¨: {e}")
    
    def forward(self, batch_dict):
        """
        âœ… CMAE-3D + R-MAE í†µí•© forward (ë…¼ë¬¸ ë…¼ë¦¬ ì¤€ìˆ˜)
        
        CMAE-3D ë…¼ë¬¸:
        - Student: masked input â†’ masked features
        - Teacher: full input â†’ full features  
        - Contrastive learning between student & teacher
        """
        voxel_features = batch_dict['voxel_features']
        voxel_coords = batch_dict['voxel_coords']
        batch_size = batch_dict['batch_size']
        
        # âœ… ë””ë²„ê¹… ì½”ë“œ ì¶”ê°€ - ì›ë³¸ ë°°ì¹˜ ì •ë³´
        original_batch_size = int(voxel_coords[:, 0].max().item()) + 1
        print(f"ğŸ” [DEBUG] Original batch size: {original_batch_size}")
        
        # ë°°ì¹˜ë³„ voxel ê°œìˆ˜ í™•ì¸
        for batch_idx in range(original_batch_size):
            batch_mask = voxel_coords[:, 0] == batch_idx
            voxel_count = batch_mask.sum().item()
            print(f"ğŸ” [DEBUG] Batch {batch_idx}: {voxel_count} voxels")
        
        # âœ… R-MAE masking ì ìš© (training ì‹œì—ë§Œ)
        if self.training and hasattr(self.model_cfg, 'PRETRAINING') and self.model_cfg.PRETRAINING:
            batch_dict['original_voxel_coords'] = voxel_coords.clone()
            batch_dict['original_voxel_features'] = voxel_features.clone()
            
            # R-MAE radial masking
            voxel_coords, voxel_features = self.radial_masking(voxel_coords, voxel_features)
            batch_dict['voxel_coords'] = voxel_coords
            batch_dict['voxel_features'] = voxel_features
            
            # âœ… ë””ë²„ê¹… ì½”ë“œ ì¶”ê°€ - ë§ˆìŠ¤í‚¹ í›„ ë°°ì¹˜ ì •ë³´
            if len(voxel_coords) > 0:
                masked_batch_size = int(voxel_coords[:, 0].max().item()) + 1
                print(f"ğŸ” [DEBUG] After masking batch size: {masked_batch_size}")
                
                # ë§ˆìŠ¤í‚¹ í›„ ë°°ì¹˜ë³„ voxel ê°œìˆ˜ í™•ì¸
                for batch_idx in range(masked_batch_size):
                    batch_mask = voxel_coords[:, 0] == batch_idx
                    voxel_count = batch_mask.sum().item()
                    print(f"ğŸ” [DEBUG] Masked Batch {batch_idx}: {voxel_count} voxels")
            else:
                print(f"ğŸ” [DEBUG] No voxels after masking!")
            
            # âœ… CMAE-3D: Teacher forward (full/unmasked input)
            if hasattr(self, 'has_teacher') and self.has_teacher:
                teacher_features = self._forward_teacher_correct(
                    batch_dict['original_voxel_coords'], 
                    batch_dict['original_voxel_features'], 
                    batch_size
                )
                batch_dict['teacher_features'] = teacher_features
                print(f"ğŸ” [DEBUG] Teacher features shape: {teacher_features.shape}")
        
        # âœ… Student network forward (masked input)
        input_sp_tensor = spconv.SparseConvTensor(
            features=voxel_features,
            indices=voxel_coords.int(),
            spatial_shape=self.sparse_shape,
            batch_size=batch_size
        )
        
        # VoxelNeXt conv layers
        x = self.conv_input(input_sp_tensor)
        x_conv1 = self.conv1(x)
        x_conv2 = self.conv2(x_conv1)  
        x_conv3 = self.conv3(x_conv2)
        x_conv4 = self.conv4(x_conv3)
        
        # âœ… Pretraining outputs
        if self.training and hasattr(self.model_cfg, 'PRETRAINING') and self.model_cfg.PRETRAINING:
            # R-MAE occupancy prediction
            occupancy_pred = self.occupancy_decoder(x_conv4)
            batch_dict['occupancy_pred'] = occupancy_pred.features
            batch_dict['occupancy_coords'] = occupancy_pred.indices
            
            # âœ… CMAE-3D: Student features
            student_features = self._extract_global_features_correct(x_conv4)
            batch_dict['student_features'] = student_features
            print(f"ğŸ” [DEBUG] Student features shape: {student_features.shape}")
                
            # âœ… CMAE-3D: Teacher EMA ì—…ë°ì´íŠ¸
            if hasattr(self, 'has_teacher') and self.has_teacher:
                self._update_teacher_ema_correct()
            
            # Multi-scale features
            batch_dict['multi_scale_features'] = {
                'x_conv1': x_conv1, 'x_conv2': x_conv2,
                'x_conv3': x_conv3, 'x_conv4': x_conv4,
            }
        
        # âœ… ê¸°ì¡´ VoxelNeXt ì¶œë ¥ í˜•ì‹ ìœ ì§€
        batch_dict.update({
            'encoded_spconv_tensor': x_conv4,
            'encoded_spconv_tensor_stride': 8,
            'multi_scale_3d_features': {
                'x_conv1': x_conv1, 'x_conv2': x_conv2,
                'x_conv3': x_conv3, 'x_conv4': x_conv4,
            }
        })
        
        return batch_dict
    
    def radial_masking(self, voxel_coords, voxel_features):
        """
        âœ… ì´ì „ ì„±ê³µ R-MAE ë¡œì§ ì™„ì „ ë³µì› (ìµœì†Œ voxel ë³´ì¥)
        """
        if not self.training:
            return voxel_coords, voxel_features
            
        batch_size = int(voxel_coords[:, 0].max()) + 1
        print(f"ğŸ” [MASKING] Processing {batch_size} batches for radial masking")
        
        masked_coords, masked_features = [], []
        
        for batch_idx in range(batch_size):
            mask = voxel_coords[:, 0] == batch_idx
            
            if not mask.any():
                print(f"ğŸ” [MASKING] Batch {batch_idx}: EMPTY - keeping empty tensors")
                # âœ… ë¹ˆ ë°°ì¹˜ë„ ë¹ˆ í…ì„œë¡œ ì¶”ê°€í•˜ì—¬ ë°°ì¹˜ ìˆœì„œ ìœ ì§€
                empty_coords = torch.empty(0, 4, dtype=voxel_coords.dtype, device=voxel_coords.device)
                empty_features = torch.empty(0, voxel_features.size(-1), dtype=voxel_features.dtype, device=voxel_features.device)
                masked_coords.append(empty_coords)
                masked_features.append(empty_features)
                continue
                
            coords_b = voxel_coords[mask]
            features_b = voxel_features[mask]
            
            print(f"ğŸ” [MASKING] Batch {batch_idx}: {len(coords_b)} voxels before masking")
            
            # âœ… ì´ì „ ì„±ê³µ ë¡œì§: ì‹¤ì œ ì¢Œí‘œ ê³„ì‚°
            voxel_size = getattr(self, 'voxel_size', [0.1, 0.1, 0.1])
            point_cloud_range = getattr(self, 'point_cloud_range', [-70, -40, -3, 70, 40, 1])
            
            x = coords_b[:, 1].float() * voxel_size[0] + point_cloud_range[0]
            y = coords_b[:, 2].float() * voxel_size[1] + point_cloud_range[1]
            theta = torch.atan2(y, x)
            
            # âœ… Angular masking (ì´ì „ ì„±ê³µ ë¡œì§)
            num_sectors = int(360 / self.angular_range)
            sector_size = 2 * np.pi / num_sectors
            keep_mask = torch.ones(len(coords_b), dtype=torch.bool, device=coords_b.device)
            
            for i in range(num_sectors):
                start = -np.pi + i * sector_size
                end = -np.pi + (i + 1) * sector_size
                in_sector = (theta >= start) & (theta < end)
                
                if in_sector.sum() > 0 and torch.rand(1) < self.masked_ratio:
                    keep_mask[in_sector] = False
            
            kept_voxels_before = keep_mask.sum().item()
            print(f"ğŸ” [MASKING] Batch {batch_idx}: {kept_voxels_before}/{len(coords_b)} voxels after initial masking")
            
            # âœ… í•µì‹¬: ìµœì†Œ voxel ë³´ì¥ (ì´ì „ ì„±ê³µ ë¡œì§ ì™„ì „ ë³µì›)
            min_keep = max(10, int(len(coords_b) * 0.1))  # ìµœì†Œ 10ê°œ ë˜ëŠ” 10%
            if keep_mask.sum() < min_keep:
                # ë§ˆìŠ¤í‚¹ëœ ê²ƒë“¤ ì¤‘ ì¼ë¶€ ë³µì›
                indices = torch.where(~keep_mask)[0]
                restore_count = min_keep - keep_mask.sum().item()
                
                if restore_count > 0 and len(indices) > 0:
                    restore_count = min(restore_count, len(indices))
                    restore_idx = indices[torch.randperm(len(indices))[:restore_count]]
                    keep_mask[restore_idx] = True
                    print(f"ğŸ”§ [MASKING] Batch {batch_idx}: Restored {restore_count} voxels to maintain minimum")
            
            kept_voxels_final = keep_mask.sum().item()
            print(f"ğŸ” [MASKING] Batch {batch_idx}: {kept_voxels_final}/{len(coords_b)} voxels kept ({kept_voxels_final/len(coords_b)*100:.1f}%)")
            
            masked_coords.append(coords_b[keep_mask])
            masked_features.append(features_b[keep_mask])
        
        # âœ… ëª¨ë“  ë°°ì¹˜ì— ëŒ€í•´ ê²°ê³¼ê°€ ìˆì–´ì•¼ í•¨
        assert len(masked_coords) == batch_size, f"Missing batches: {len(masked_coords)} != {batch_size}"
        
        if masked_coords:
            result_coords = torch.cat(masked_coords, dim=0)
            result_features = torch.cat(masked_features, dim=0)
            
            print(f"ğŸ” [MASKING] Final result: {len(result_coords)} total voxels")
            return result_coords, result_features
        else:
            print(f"âš ï¸ [MASKING] No voxels remained after masking! Returning original")
            return voxel_coords, voxel_features
    
    def _forward_teacher_correct(self, original_coords, original_features, batch_size):
        """
        â• CMAE Teacher network forward (ë…¼ë¬¸ ë…¼ë¦¬ ì¤€ìˆ˜)
        
        CMAE-3D ë…¼ë¬¸:
        - TeacherëŠ” full/unmasked input ì²˜ë¦¬
        - Studentì™€ ë™ì¼í•œ forward pass
        """
        if not (hasattr(self, 'has_teacher') and self.has_teacher):
            # Teacher ì—†ìœ¼ë©´ Student features ì‚¬ìš© (ë…¼ë¬¸ì—ì„œëŠ” ì´ëŸ° ê²½ìš° ì—†ìŒ)
            return torch.randn(1, 256, device=original_features.device)
        
        try:
            with torch.no_grad():  # TeacherëŠ” gradient ê³„ì‚° ì—†ìŒ
                # âœ… CMAE-3D: Teacher forward (unmasked input)
                input_sp_tensor = spconv.SparseConvTensor(
                    features=original_features,
                    indices=original_coords.int(),
                    spatial_shape=self.sparse_shape,
                    batch_size=batch_size
                )
                
                # Teacher VoxelNeXt forward
                t_x = self.teacher_backbone.conv_input(input_sp_tensor)
                t_x_conv1 = self.teacher_backbone.conv1(t_x)
                t_x_conv2 = self.teacher_backbone.conv2(t_x_conv1)
                t_x_conv3 = self.teacher_backbone.conv3(t_x_conv2)
                t_x_conv4 = self.teacher_backbone.conv4(t_x_conv3)
                
                # Global features ì¶”ì¶œ
                teacher_features = self._extract_global_features_correct(t_x_conv4)
                
                return teacher_features
                
        except Exception as e:
            print(f"âš ï¸ Teacher forward ì‹¤íŒ¨: {e}")
            return torch.randn(1, 256, device=original_features.device)
    
    def _extract_global_features_correct(self, sparse_tensor):
        """
        âœ… ì˜¬ë°”ë¥¸ CMAE Global feature extraction (ë°°ì¹˜ë³„ ì²˜ë¦¬)
        """
        try:
            if hasattr(sparse_tensor, 'features') and hasattr(sparse_tensor, 'indices'):
                features = sparse_tensor.features  # [N, C]
                indices = sparse_tensor.indices    # [N, 4] (batch, z, y, x)
            else:
                # Fallback
                return torch.randn(1, 256, device=sparse_tensor.device)
            
            if features.size(0) == 0:
                return torch.randn(1, 256, device=features.device)
            
            # âœ… ë°°ì¹˜ë³„ë¡œ global feature ì¶”ì¶œ
            batch_indices = indices[:, 0]  # batch indices
            batch_size = int(batch_indices.max().item()) + 1
            
            batch_features = []
            for batch_idx in range(batch_size):
                # í˜„ì¬ ë°°ì¹˜ì˜ featuresë§Œ ì¶”ì¶œ
                batch_mask = batch_indices == batch_idx
                batch_feat = features[batch_mask]  # [N_batch, C]
                
                if batch_feat.size(0) > 0:
                    # Global average pooling for this batch
                    global_feat = torch.mean(batch_feat, dim=0, keepdim=True)  # [1, C]
                else:
                    # Empty batch handling
                    global_feat = torch.zeros(1, features.size(-1), device=features.device)
                
                batch_features.append(global_feat)
            
            # Stack all batch features
            result = torch.cat(batch_features, dim=0)  # [batch_size, C]
            
            # Project to target dimension
            if hasattr(self, 'student_projector'):
                projected = self.student_projector(result)
            else:
                # Dimension adjustment
                if result.size(-1) != 256:
                    if result.size(-1) >= 256:
                        projected = result[:, :256]
                    else:
                        padding = 256 - result.size(-1)
                        projected = F.pad(result, (0, padding))
                else:
                    projected = result
            
            return projected  # [batch_size, 256] â† ì´ì œ ì˜¬ë°”ë¥¸ shape!
            
        except Exception as e:
            print(f"âš ï¸ Global feature extraction ì‹¤íŒ¨: {e}")
            # Fallback to batch_size=1
            device = sparse_tensor.features.device if hasattr(sparse_tensor, 'features') else sparse_tensor.device
            return torch.randn(1, 256, device=device)
    
    def _update_teacher_ema_correct(self):
        """
        â• CMAE Teacher EMA update (ë…¼ë¬¸ ë…¼ë¦¬ ì¤€ìˆ˜)
        
        CMAE-3D ë…¼ë¬¸: Î¸_teacher = momentum * Î¸_teacher + (1-momentum) * Î¸_student
        """
        if not (hasattr(self, 'has_teacher') and self.has_teacher):
            return
        
        try:
            with torch.no_grad():
                # âœ… CMAE-3D EMA ì—…ë°ì´íŠ¸ (momentum=0.999)
                teacher_modules = dict(self.teacher_backbone.named_modules())
                student_modules = dict(self.named_modules())
                
                # conv layers EMA ì—…ë°ì´íŠ¸
                layer_names = ['conv_input', 'conv1', 'conv2', 'conv3', 'conv4']
                
                for layer_name in layer_names:
                    if layer_name in teacher_modules and layer_name in student_modules:
                        self._ema_update_layer_correct(
                            student_modules[layer_name],
                            teacher_modules[layer_name]
                        )
                
                # Feature projectors EMA ì—…ë°ì´íŠ¸
                if hasattr(self, 'teacher_projector') and hasattr(self, 'student_projector'):
                    for t_param, s_param in zip(
                        self.teacher_projector.parameters(),
                        self.student_projector.parameters()
                    ):
                        t_param.data.mul_(self.momentum).add_(
                            s_param.data, alpha=1.0 - self.momentum
                        )
                        
        except Exception as e:
            print(f"âš ï¸ Teacher EMA update ì‹¤íŒ¨: {e}")
    
    def _ema_update_layer_correct(self, student_layer, teacher_layer):
        """CMAE-3D ë…¼ë¬¸ ê¸°ì¤€ EMA ì—…ë°ì´íŠ¸"""
        try:
            student_params = list(student_layer.parameters())
            teacher_params = list(teacher_layer.parameters())
            
            for s_param, t_param in zip(student_params, teacher_params):
                if s_param.shape == t_param.shape:
                    # CMAE-3D EMA: Î¸_t = m*Î¸_t + (1-m)*Î¸_s
                    t_param.data.mul_(self.momentum).add_(
                        s_param.data, alpha=1.0 - self.momentum
                    )
                        
        except Exception as e:
            print(f"âš ï¸ Layer EMA ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")


# âœ… ëª¨ë¸ ë“±ë¡ì„ ìœ„í•œ alias
RMAECMAEBackbone = RMAECMAEBackbone