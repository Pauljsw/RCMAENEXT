# pcdet/models/backbones_3d/components/frame_contrastive_loss.py
"""
CMAE-3D Phase 2: Frame-level Contrastive Learning

CMAE-3D ë…¼ë¬¸ì˜ í•µì‹¬ ì•„ì´ë””ì–´:
- ì¸ì ‘ í”„ë ˆì„ ê°„ semantic similarity ê°•í™” (ì‹œê°„ì  ì¼ê´€ì„±)
- False negative ë¬¸ì œ ì™„í™” (ê°™ì€ ê°ì²´ê°€ ì—°ì† í”„ë ˆì„ì—ì„œ ë‹¤ë¥´ê²Œ ì¸ì‹ë˜ëŠ” ë¬¸ì œ)
- Memory bankë¥¼ í†µí•œ temporal feature ê´€ë¦¬
- ê±´ì„¤ì¥ë¹„ ë„ë©”ì¸ íŠ¹í™”: ê°™ì€ ì¥ë¹„ íƒ€ì… = positive, ë‹¤ë¥¸ ì¥ë¹„ íƒ€ì… = negative

ì´ ëª¨ë“ˆì€ frame-levelì—ì„œ temporal consistencyë¥¼ í•™ìŠµí•˜ì—¬ 
robustí•˜ê³  temporally consistentí•œ representationì„ êµ¬ì¶•í•©ë‹ˆë‹¤.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from collections import deque


class FrameContrastiveLoss(nn.Module):
    """
    ğŸ”¥ CMAE-3D Frame-level Contrastive Learning
    
    í•µì‹¬ ì•„ì´ë””ì–´:
    1. Memory bank: ì´ì „ í”„ë ˆì„ë“¤ì˜ features ì €ì¥
    2. Temporal consistency: ì¸ì ‘ í”„ë ˆì„ ê°„ similarity ê°•í™”  
    3. Domain-specific: ê±´ì„¤ì¥ë¹„ íƒ€ì…ë³„ positive/negative êµ¬ë¶„
    4. False negative ì™„í™”: ê°™ì€ ì¥ë¹„ì˜ ì—°ì† í”„ë ˆì„ = positive
    5. InfoNCE + Momentum update í™œìš©
    """
    
    def __init__(self, model_cfg):
        super().__init__()
        
        # Frame contrastive learning ì„¤ì •
        self.temperature = model_cfg.get('FRAME_TEMPERATURE', 0.1)  # Frame-level temperature (ë‚®ê²Œ ì„¤ì •)
        self.feature_dim = model_cfg.get('FEATURE_DIM', 128)
        self.projection_dim = model_cfg.get('PROJECTION_DIM', 128)
        
        # Memory bank ì„¤ì • (temporal consistency)
        self.memory_bank_size = model_cfg.get('MEMORY_BANK_SIZE', 16)  # ìµœê·¼ 16 í”„ë ˆì„ ì €ì¥
        self.momentum = model_cfg.get('MOMENTUM_UPDATE', 0.99)  # Momentum update coefficient
        
        # Equipment type contrastive learning ì„¤ì •
        self.enable_domain_specific = model_cfg.get('ENABLE_DOMAIN_SPECIFIC', True)
        self.equipment_types = model_cfg.get('EQUIPMENT_TYPES', ['dumptruck', 'excavator', 'grader', 'roller'])
        
        # Negative sampling ì„¤ì •
        self.max_negatives = model_cfg.get('MAX_FRAME_NEGATIVES', 1024)
        self.hard_negative_ratio = model_cfg.get('HARD_NEGATIVE_RATIO', 0.2)  # 20% hard negatives
        
        # ğŸ“ Feature Projection Head
        self.frame_projector = self._build_projection_head(self.feature_dim, self.projection_dim)
        
        # ğŸ“ Memory Bank ì´ˆê¸°í™” (queue êµ¬ì¡°)
        self.register_buffer('memory_bank', torch.randn(self.memory_bank_size, self.projection_dim))
        self.register_buffer('memory_timestamps', torch.zeros(self.memory_bank_size))
        self.register_buffer('memory_equipment_types', torch.zeros(self.memory_bank_size))
        self.register_buffer('bank_ptr', torch.zeros(1, dtype=torch.long))
        
        # L2 normalize memory bank
        self.memory_bank = F.normalize(self.memory_bank, dim=1)
        
        print(f"ğŸ”¥ Frame Contrastive Loss initialized:")
        print(f"   - Frame temperature: {self.temperature}")
        print(f"   - Memory bank size: {self.memory_bank_size}")
        print(f"   - Momentum update: {self.momentum}")
        print(f"   - Domain-specific: {self.enable_domain_specific}")
        print(f"   - Equipment types: {self.equipment_types}")
    
    def _build_projection_head(self, input_dim, output_dim):
        """Frame-level contrastive learningì„ ìœ„í•œ projection head"""
        return nn.Sequential(
            nn.Linear(input_dim, input_dim),
            nn.ReLU(inplace=True),
            nn.Linear(input_dim, output_dim),
            nn.BatchNorm1d(output_dim)
        )
    
    @torch.no_grad()
    def _update_memory_bank(self, features, timestamps, equipment_types):
        """
        Memory bankë¥¼ momentum updateë¡œ ê°±ì‹ 
        
        Args:
            features: [B, projection_dim] Current frame features  
            timestamps: [B] Frame timestamps
            equipment_types: [B] Equipment type indices
        """
        batch_size = features.size(0)
        ptr = int(self.bank_ptr)
        
        # Circular queue update
        if ptr + batch_size <= self.memory_bank_size:
            # Normal case: ì¶©ë¶„í•œ ê³µê°„
            self.memory_bank[ptr:ptr+batch_size] = features
            self.memory_timestamps[ptr:ptr+batch_size] = timestamps
            self.memory_equipment_types[ptr:ptr+batch_size] = equipment_types
            ptr = (ptr + batch_size) % self.memory_bank_size
        else:
            # Wrap around case: queue ëì— ë„ë‹¬
            remaining = self.memory_bank_size - ptr
            self.memory_bank[ptr:] = features[:remaining]
            self.memory_bank[:batch_size-remaining] = features[remaining:]
            
            self.memory_timestamps[ptr:] = timestamps[:remaining]
            self.memory_timestamps[:batch_size-remaining] = timestamps[remaining:]
            
            self.memory_equipment_types[ptr:] = equipment_types[:remaining]
            self.memory_equipment_types[:batch_size-remaining] = equipment_types[remaining:]
            
            ptr = batch_size - remaining
        
        self.bank_ptr[0] = ptr
    
    def _find_temporal_positives(self, current_timestamps, current_equipment_types):
        """
        Temporal positive pairs ì°¾ê¸°
        
        Positive ì¡°ê±´:
        1. ì‹œê°„ì ìœ¼ë¡œ ê°€ê¹Œìš´ í”„ë ˆì„ (Â±2 í”„ë ˆì„ ì´ë‚´)
        2. ê°™ì€ ì¥ë¹„ íƒ€ì… (domain-specific)
        
        Returns:
            positive_mask: [B, memory_bank_size] Boolean mask
        """
        batch_size = current_timestamps.size(0)
        positive_mask = torch.zeros(batch_size, self.memory_bank_size, dtype=torch.bool, device=current_timestamps.device)
        
        for i in range(batch_size):
            curr_time = current_timestamps[i]
            curr_type = current_equipment_types[i]
            
            # ì‹œê°„ì  ê·¼ì ‘ì„± ì²´í¬ (Â±2 í”„ë ˆì„)
            time_diff = torch.abs(self.memory_timestamps - curr_time)
            temporal_close = time_diff <= 2.0  # 2 í”„ë ˆì„ ì´ë‚´
            
            if self.enable_domain_specific:
                # ë„ë©”ì¸ íŠ¹í™”: ê°™ì€ ì¥ë¹„ íƒ€ì…
                same_equipment = self.memory_equipment_types == curr_type
                positive_mask[i] = temporal_close & same_equipment
            else:
                # ì¼ë°˜ì : ì‹œê°„ì  ê·¼ì ‘ì„±ë§Œ
                positive_mask[i] = temporal_close
        
        return positive_mask
    
    def _compute_frame_infonce_loss(self, current_proj, positive_mask):
        """
        Frame-level InfoNCE loss ê³„ì‚°
        
        ê° current frameì— ëŒ€í•´:
        - Positives: Memory bankì—ì„œ temporal + domain ì¡°ê±´ ë§Œì¡±í•˜ëŠ” frames
        - Negatives: ë‚˜ë¨¸ì§€ ëª¨ë“  frames
        """
        batch_size = current_proj.size(0)
        
        if positive_mask.sum() == 0:
            # No positive pairs
            return torch.tensor(0.0, device=current_proj.device, requires_grad=True), {
                'frame_accuracy': 0.0, 'avg_positives': 0.0
            }
        
        # Cosine similarity: [B, memory_bank_size]
        similarity = torch.matmul(current_proj, self.memory_bank.T) / self.temperature
        
        total_loss = 0.0
        correct_predictions = 0
        total_positives = 0
        
        for i in range(batch_size):
            pos_mask = positive_mask[i]  # [memory_bank_size]
            num_positives = pos_mask.sum().item()
            
            if num_positives == 0:
                continue
            
            # Positive similarities
            pos_sim = similarity[i][pos_mask]  # [num_positives]
            
            # All similarities (positives + negatives)
            all_sim = similarity[i]  # [memory_bank_size]
            
            # InfoNCE loss for each positive
            pos_exp = torch.exp(pos_sim)
            all_exp = torch.exp(all_sim).sum()
            
            # Average over positives
            sample_loss = -torch.log(pos_exp.sum() / all_exp)
            total_loss += sample_loss
            
            # Accuracy: positiveê°€ ê°€ì¥ ë†’ì€ similarityë¥¼ ê°€ì§€ëŠ”ì§€
            max_sim_idx = all_sim.argmax()
            if pos_mask[max_sim_idx]:
                correct_predictions += 1
                
            total_positives += num_positives
        
        if batch_size == 0:
            return torch.tensor(0.0, device=current_proj.device, requires_grad=True), {
                'frame_accuracy': 0.0, 'avg_positives': 0.0
            }
        
        avg_loss = total_loss / batch_size
        accuracy = correct_predictions / batch_size if batch_size > 0 else 0.0
        avg_positives = total_positives / batch_size if batch_size > 0 else 0.0
        
        return avg_loss, {
            'frame_accuracy': accuracy,
            'avg_positives': avg_positives
        }
    
    def forward(self, current_features, timestamps, equipment_types):
        """
        Frame-level contrastive learning forward pass
        
        Args:
            current_features: [B, feature_dim] Current frame features
            timestamps: [B] Frame timestamps (frame indices)  
            equipment_types: [B] Equipment type indices (0: dumptruck, 1: excavator, ...)
        
        Returns:
            frame_contrastive_results: Dict containing frame contrastive loss and stats
        """
        batch_size = current_features.size(0)
        
        # ğŸ“ 1. Feature Projection
        current_proj = self.frame_projector(current_features)  # [B, projection_dim]
        current_proj = F.normalize(current_proj, dim=1)
        
        # ğŸ“ 2. Find Temporal Positive Pairs
        positive_mask = self._find_temporal_positives(timestamps, equipment_types)
        
        # ğŸ“ 3. Compute Frame InfoNCE Loss
        frame_loss, stats = self._compute_frame_infonce_loss(current_proj, positive_mask)
        
        # ğŸ“ 4. Update Memory Bank (no grad)
        with torch.no_grad():
            self._update_memory_bank(current_proj.detach(), timestamps, equipment_types)
        
        return {
            'frame_contrastive_loss': frame_loss,
            'frame_accuracy': stats['frame_accuracy'],
            'avg_temporal_positives': stats['avg_positives'],
            'memory_bank_usage': int(self.bank_ptr[0].item()),
            'total_positives': positive_mask.sum().item()
        }
    
    def get_memory_bank_status(self):
        """Memory bank ìƒíƒœ ì •ë³´ ë°˜í™˜ (debuggingìš©)"""
        return {
            'bank_size': self.memory_bank_size,
            'current_usage': int(self.bank_ptr[0].item()),
            'momentum': self.momentum,
            'temperature': self.temperature
        }