"""
pcdet/models/backbones_3d/radial_mae_voxelnext_clean.py

R-MAE + VoxelNeXt Clean Implementation
ê³µì‹ R-MAE GitHub ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê¹”ë”í•œ ì¬êµ¬ì„±

í•µì‹¬ ë³€ê²½ì‚¬í•­:
1. ê³µì‹ R-MAEì˜ ë‹¨ìˆœí•œ radial masking ë¡œì§ ì°¨ìš©
2. ë³µì¡í•œ 2-stage masking ì œê±°
3. VoxelNeXt backbone ìœ ì§€í•˜ë©´ì„œ R-MAE ê¸°ëŠ¥ í†µí•©
"""

import torch
import torch.nn as nn
import spconv.pytorch as spconv
from functools import partial
import numpy as np
from .spconv_backbone_voxelnext import VoxelResBackBone8xVoxelNeXt


class RadialMAEVoxelNeXtClean(VoxelResBackBone8xVoxelNeXt):
    """
    ğŸ¯ Clean R-MAE + VoxelNeXt Implementation
    
    ê³µì‹ R-MAE ì½”ë“œ ê¸°ë°˜ì˜ ë‹¨ìˆœí•˜ê³  íš¨ê³¼ì ì¸ êµ¬í˜„:
    - ë‹¨ìˆœí•œ radial masking (ê³µì‹ ì½”ë“œ ìŠ¤íƒ€ì¼)
    - VoxelNeXt backbone ì™„ì „ í˜¸í™˜
    - ê¹”ë”í•œ occupancy prediction
    """
    
    def __init__(self, model_cfg, input_channels, grid_size, voxel_size, point_cloud_range, **kwargs):
        # VoxelNeXt backbone ì´ˆê¸°í™”
        super().__init__(model_cfg, input_channels, grid_size, **kwargs)
        
        # R-MAE íŒŒë¼ë¯¸í„° (ê³µì‹ ì½”ë“œ ìŠ¤íƒ€ì¼)
        self.masked_ratio = model_cfg.get('MASKED_RATIO', 0.8)
        self.angular_range = model_cfg.get('ANGULAR_RANGE', 1)  # ê³µì‹ ê¸°ë³¸ê°’: 1ë„
        
        # VoxelNeXt í˜¸í™˜ì„ ìœ„í•œ ì†ì„±
        self.voxel_size = voxel_size
        self.point_cloud_range = point_cloud_range
        
        # âœ… R-MAE Occupancy Decoder (ê°„ë‹¨í•˜ê³  íš¨ê³¼ì )
        if hasattr(model_cfg, 'PRETRAINING') and model_cfg.PRETRAINING:
            self.occupancy_decoder = self._build_occupancy_decoder()
            self.criterion = nn.BCEWithLogitsLoss()  # ê³µì‹ê³¼ ë™ì¼
            
        print(f"ğŸ¯ Clean R-MAE Implementation:")
        print(f"   - Masked ratio: {self.masked_ratio}")
        print(f"   - Angular range: {self.angular_range}Â°")
        print(f"   - Pretraining mode: {getattr(model_cfg, 'PRETRAINING', False)}")
    
    def _build_occupancy_decoder(self):
        """ê³µì‹ R-MAE ìŠ¤íƒ€ì¼ì˜ ê°„ë‹¨í•œ decoder"""
        norm_fn = partial(nn.BatchNorm1d, eps=1e-3, momentum=0.01)
        
        return spconv.SparseSequential(
            # 128 -> 64
            spconv.SubMConv3d(128, 64, 3, padding=1, bias=False, indice_key='mae_dec1'),
            norm_fn(64), nn.ReLU(),
            # 64 -> 32  
            spconv.SubMConv3d(64, 32, 3, padding=1, bias=False, indice_key='mae_dec2'),
            norm_fn(32), nn.ReLU(),
            # 32 -> 1 (occupancy)
            spconv.SubMConv3d(32, 1, 1, bias=True, indice_key='mae_out')
        )
    
    def radial_masking_official_style(self, voxel_coords, voxel_features):
        """
        ğŸ”¥ ê³µì‹ R-MAE ì½”ë“œ ê¸°ë°˜ì˜ ë‹¨ìˆœí•˜ê³  íš¨ê³¼ì ì¸ radial masking
        
        ë³µì¡í•œ 2-stage ì œê±°í•˜ê³  ê³µì‹ì˜ ê°„ë‹¨í•œ ë¡œì§ ì‚¬ìš©:
        1. Distance-based grouping (30m, 50m ê¸°ì¤€)
        2. Angular grouping (angular_range ë‹¨ìœ„)  
        3. ê° ê·¸ë£¹ì—ì„œ uniform sampling
        """
        if not self.training:
            return voxel_coords, voxel_features
            
        # ğŸ“ ê³µì‹ ì½”ë“œì™€ ë™ì¼í•œ ê±°ë¦¬ ê³„ì‚°
        voxel_coords_distance = (voxel_coords[:, 2]**2 + voxel_coords[:, 3]**2)**0.5
        
        # ğŸ“ ê³µì‹ ì½”ë“œì™€ ë™ì¼í•œ ê±°ë¦¬ë³„ ê·¸ë£¹í•‘ (30m, 50m ê¸°ì¤€)
        select_30 = voxel_coords_distance <= 30
        select_30to50 = (voxel_coords_distance > 30) & (voxel_coords_distance <= 50)  
        select_50 = voxel_coords_distance > 50
        
        # ğŸ“ ê°ë„ ê³„ì‚° (ê³µì‹ê³¼ ë™ì¼)
        angles = torch.atan2(voxel_coords[:, 3], voxel_coords[:, 2])  # atan2(y, x)
        angles_deg = torch.rad2deg(angles) % 360
        
        # ğŸ“ Selection ratio ê³„ì‚° (ê³µì‹ê³¼ ë™ì¼)
        select_ratio = 1 - self.masked_ratio
        
        selected_indices = []
        
        # ğŸ“ ê° ê±°ë¦¬ ê·¸ë£¹ë³„ë¡œ ë™ì¼í•œ ë¹„ìœ¨ë¡œ sampling
        for distance_mask, group_name in [(select_30, "near"), (select_30to50, "mid"), (select_50, "far")]:
            group_indices = torch.where(distance_mask)[0]
            
            if len(group_indices) == 0:
                continue
                
            # ì´ ê·¸ë£¹ì—ì„œ ì„ íƒí•  ê°œìˆ˜
            num_to_select = int(len(group_indices) * select_ratio)
            
            if num_to_select > 0:
                # Angular grouping ì ìš© (ê³µì‹ ìŠ¤íƒ€ì¼)
                group_coords = voxel_coords[group_indices]
                group_angles = angles_deg[group_indices]
                
                # ê° angular segmentì—ì„œ uniform sampling
                for angle_start in range(0, 360, self.angular_range):
                    angle_end = angle_start + self.angular_range
                    angular_mask = (group_angles >= angle_start) & (group_angles < angle_end)
                    angular_indices = group_indices[angular_mask]
                    
                    if len(angular_indices) > 0:
                        # ì´ angular segmentì—ì„œ ì„ íƒí•  ê°œìˆ˜ ê³„ì‚°
                        segment_select_num = int(len(angular_indices) * select_ratio)
                        if segment_select_num > 0:
                            # Random sampling
                            perm = torch.randperm(len(angular_indices))[:segment_select_num]
                            selected_indices.extend(angular_indices[perm].tolist())
        
        # ğŸ“ ìµœì¢… ì„ íƒëœ voxelë“¤ ë°˜í™˜
        if len(selected_indices) > 0:
            selected_indices = torch.tensor(selected_indices, device=voxel_coords.device)
            masked_coords = voxel_coords[selected_indices]
            masked_features = voxel_features[selected_indices]
        else:
            # Fallback: ì „ì²´ì—ì„œ random sampling
            num_total_select = int(len(voxel_coords) * select_ratio)
            perm = torch.randperm(len(voxel_coords))[:num_total_select]
            masked_coords = voxel_coords[perm]
            masked_features = voxel_features[perm]
            
        return masked_coords, masked_features
    
    def forward(self, batch_dict):
        """
        ğŸ”¥ Clean forward pass
        
        ê³µì‹ R-MAE ìŠ¤íƒ€ì¼ë¡œ ë‹¨ìˆœí™”:
        1. Masking ì ìš© (trainingì‹œì—ë§Œ)
        2. VoxelNeXt backbone ì‹¤í–‰
        3. Occupancy prediction (pretrainingì‹œì—ë§Œ)
        """
        voxel_features = batch_dict['voxel_features']
        voxel_coords = batch_dict['voxel_coords']
        batch_size = batch_dict['batch_size']
        
        # ğŸ“ R-MAE Masking (training ì‹œì—ë§Œ)
        if self.training and hasattr(self.model_cfg, 'PRETRAINING') and self.model_cfg.PRETRAINING:
            # ì›ë³¸ ì €ì¥ (loss ê³„ì‚°ìš©)
            batch_dict['original_voxel_coords'] = voxel_coords.clone()
            
            # ê³µì‹ ìŠ¤íƒ€ì¼ì˜ ê°„ë‹¨í•œ masking ì ìš©
            voxel_coords, voxel_features = self.radial_masking_official_style(voxel_coords, voxel_features)
            
            batch_dict['voxel_coords'] = voxel_coords
            batch_dict['voxel_features'] = voxel_features
            
            # Masking í†µê³„
            original_count = len(batch_dict['original_voxel_coords'])
            current_count = len(voxel_coords)
            actual_mask_ratio = 1.0 - (current_count / original_count) if original_count > 0 else 0.0
            print(f"ğŸ¯ R-MAE Masking: {original_count} â†’ {current_count} (mask ratio: {actual_mask_ratio:.2f})")
        
        # ğŸ“ VoxelNeXt Backbone ì‹¤í–‰ (ê¸°ì¡´ê³¼ ë™ì¼)
        input_sp_tensor = spconv.SparseConvTensor(
            features=voxel_features,
            indices=voxel_coords.int(),
            spatial_shape=self.sparse_shape,
            batch_size=batch_size
        )
        
        # VoxelNeXt conv layers
        x = self.conv_input(input_sp_tensor)
        x_conv1 = self.conv1(x)
        x_conv2 = self.conv2(x_conv1)
        x_conv3 = self.conv3(x_conv2)
        x_conv4 = self.conv4(x_conv3)
        
        # ğŸ“ R-MAE Occupancy Prediction (pretraining ì‹œì—ë§Œ)
        if self.training and hasattr(self.model_cfg, 'PRETRAINING') and self.model_cfg.PRETRAINING:
            occupancy_pred = self.occupancy_decoder(x_conv4)
            batch_dict['occupancy_pred'] = occupancy_pred.features
            batch_dict['occupancy_coords'] = occupancy_pred.indices
        
        # ğŸ“ VoxelNeXt ì¶œë ¥ í˜•ì‹ ìœ ì§€ (í˜¸í™˜ì„±)
        batch_dict.update({
            'encoded_spconv_tensor': x_conv4,
            'encoded_spconv_tensor_stride': 8,
            'multi_scale_3d_features': {
                'x_conv1': x_conv1, 'x_conv2': x_conv2,
                'x_conv3': x_conv3, 'x_conv4': x_conv4,
            }
        })
        
        return batch_dict
    
    def get_loss(self, tb_dict=None):
        """
        ğŸ”¥ ê³µì‹ R-MAE ìŠ¤íƒ€ì¼ì˜ ê°„ë‹¨í•œ loss ê³„ì‚°
        
        ë³µì¡í•œ distance weighting, focal loss ë“± ëª¨ë‘ ì œê±°í•˜ê³ 
        ê³µì‹ì˜ ë‹¨ìˆœí•œ BCEWithLogitsLossë§Œ ì‚¬ìš©
        """
        if not hasattr(self, 'forward_re_dict') or 'pred' not in self.forward_re_dict:
            # Fallback loss
            dummy_loss = torch.tensor(0.1, requires_grad=True, device='cuda')
            return dummy_loss, {'loss_rpn': 0.1}
            
        pred = self.forward_re_dict['pred']
        target = self.forward_re_dict['target']
        
        # ê³µì‹ê³¼ ë™ì¼í•œ ë‹¨ìˆœí•œ loss
        loss = self.criterion(pred, target)
        
        tb_dict = tb_dict or {}
        tb_dict.update({
            'loss_rpn': loss.item(),
            'occupancy_loss': loss.item()
        })
        
        return loss, tb_dict